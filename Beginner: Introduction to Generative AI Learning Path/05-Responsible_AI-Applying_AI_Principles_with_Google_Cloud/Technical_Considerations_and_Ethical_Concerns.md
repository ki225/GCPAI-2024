# AI Technical Considerations and Ethical Concerns


1. **道德兩難 (Ethical Dilemma)**：這是一種情境，必須在多個行動方案中做出艱難的選擇，通常每個選擇都涉及違背某些道德原則。例子包括朋友即將被解僱，但你被要求保密，而朋友正打算購買新房，這樣的情境需要審視個人的價值觀來做出決定。
2. **道德誘惑 (Moral Temptation)**：這不同於道德兩難，誘惑是指在正確和錯誤之間做選擇，並且錯誤的選擇對自己有利。例如，離開電影院時發現沒人查票，是否免費進入觀看另一部電影。
3. **AI 相關的道德挑戰**：AI 的發展會帶來許多道德上的兩難，因為其技術對社會的影響深遠。負責任的 AI 開發成為關鍵，數位信任是推動 AI 工具採用的核心。
4. **道德與法律的差異**：倫理反映的是彼此的價值觀和期望，不是所有的道德問題都有法律的約束。很多不道德的行為是合法的，如撒謊、違背承諾等；而某些英勇的公民抗命行為則可能是非法的。
5. **負責任 AI 的需求**：隨著技術的進步，AI 可能會迅速、廣泛地無意中複製某些有害行為。因此，AI 的開發需要謹慎考慮其道德影響。許多組織開始制定道德規章來指導 AI 的發展，並致力於建立用戶信任。
6. **企業的道德責任**：企業在定義倫理時應考慮與用戶、團隊及更廣泛社會的信任關係，這些關係是企業成功的基礎。

## AI ethical concerns

1. **透明性（Transparency）**：隨著AI系統變得更複雜，透明度逐漸減少，讓使用者難以理解系統如何作出決策。透明性對於自主性、預測AI系統可能失效的情況以及改善AI系統至關重要。
2. **不公平偏見（Unfair Bias）**：AI並不會自己產生偏見，而是反映了社會中的偏見。AI的擴展性可能會加劇不公平，這樣的偏見來自於訓練數據集的選擇和社會背景。
3. **安全性（Security）**：AI系統的安全性同樣面臨挑戰。惡意行為者可能會利用AI的漏洞進行攻擊，AI帶來的數據量也增加了敏感數據外洩的風險。
4. **隱私（Privacy）**：AI能夠收集和處理大量的數據，這增加了隱私侵犯的風險，包括身份跟蹤、語音和面部識別的濫用等。
5. **AI偽科學（AI Pseudoscience）**：一些AI系統可能聲稱具備無科學依據的能力，如犯罪傾向預測和情緒檢測，這些不實的聲稱可能會對個人和社會造成危害。
6. **對人的責任（Accountability to People）**：AI系統應該滿足所有人的需求，並確保適當的人類干預。透明度和對系統進行反饋的能力是達到責任的重要方式。
7. **AI驅動的失業與技能退化（AI-driven Unemployment and Deskilling）**：AI可能會取代部分工作，導致失業和技能退化的問題，雖然新技術同時也會創造新的就業機會。
8. **生成式AI的特定議題（Generative AI Concerns）**：生成式AI引發的特定問題包括「幻覺」(虛構信息生成)、「事實性」(生成內容的真實性)和「擬人化」(將AI視作具備人類特質)。
9. **倫理問題的根源**：根據調查，倫理問題主要來自於資源不足、缺乏多樣化的團隊，以及缺少明確的倫理守則。企業在實施AI時面臨的壓力也是倫理問題的一個主要來源。
10. **AI的社會貢獻**：儘管存在風險，AI同樣可以在醫療、設計、預測系統等領域帶來巨大益處，負責任的AI實踐可以幫助確保這些益處惠及所有人。

