# Operationalizing AI Principles: Issue Spotting and Lessons Learned

## Issue Spotting process 

### 1. 問題發現過程
- **問題識別**：針對 AI 使用案例，確定潛在的倫理問題。
- **重要性**：需避免使用簡單的檢查清單，因為這會妨礙批判性分析。
### 2. 批判性思考問題
- **問題設計**：問題基於成熟的倫理決策框架，強調尋求額外信息及考慮最佳與最壞情境。
- **主要主題**：問題涵蓋產品定義、解決的問題、預期用戶、數據來源、模型訓練和測試等。
### 3. 針對具體情境的問題
- **情境分析**：考慮使用案例的目的、社會益處及潛在濫用情境。
- **設計決策的影響**：強調設計決策可能影響公平與負責任的 AI 使用。
### 4. 假設與深入審查
- **問題假設**：假設總有可以解決的問題，即使使用案例看似社會有益。
- **深入評估**：若在批判性思考過程中發現衝突的倫理問題，則進行更深入的審查。
### 5. 複雜領域的倫理審查
- **關鍵領域**：特定的風險和危害需要進一步的倫理審查，例如監控或合成媒體等使用案例。
### 6. 實際案例分析
- **案例介紹**：以「自閉症譜系障礙照護機器人」(ASD Carebot)為例進行問題發現。
- **社會效益**：擴大對未普及治療的接觸，但需考量這是否是最合適的方式。
### 7. 問題發現問題範例
- **利益相關者**：考慮產品利益相關者的需求與期望。
- **公平性**：檢討團隊如何影響模型的公平性，以及數據來源的代表性。
- **安全性與隱私**：評估模型的表現不如預期的風險，及 Carebot 收集的數據類型及隱私風險。
- **責任感**：確保系統的人類監督及適當的知情同意。
### 8. 科學與技術專業
- **專業評估**：評估產品開發團隊的專業知識，是否需與專業合作夥伴合作。
### 9. 計畫的可用性
- **可及性考量**：確保解決方案能夠廣泛提供給用戶，強調可負擔性和可及性。

## 最佳實踐

1. **多元化審查委員會**：
   - 組成具有文化身份、專業知識和資歷多樣性的審查委員會，以反映當前或潛在的用戶群體。
   - 考慮多元性、公平性和包容性（DEI），促進更具信息性的決策，導致可行的解決方案。
2. **獲得全方位支持**：
   - 需要自上而下的支持（高層領導的認可）與自下而上的參與，確保組織內部的文化轉型和負責任AI的普及。
3. **教育與培訓**：
   - 針對技術團隊與非技術利益相關者進行技術倫理教育，幫助建立負責任AI的公司文化。
4. **對齊商業目標與責任AI**：
   - 確保業務與負責任AI團隊的目標一致，釋放符合所有人利益的產品有助於商業成功。
5. **提高透明度**：
   - 在負責任AI治理過程中追求透明度，以建立信任。保留機密性同時，增進過程透明度以增強信譽。
6. **系統性記錄**：
   - 建立系統以追蹤計畫的一致性，包括問題、緩解措施和先例，為未來工作提供資訊。
7. **謙虛的態度**：
   - 在快速變化的AI環境中，保持學習的心態，隨時準備改進與調整。
8. **心理安全**：
   - 建立心理安全感，使團隊能夠自由地探索可能的問題與使用不當的情境，促進深入的對話。
9. **效率不是首要目標**：
   - 在產品開發目標與全面AI審查之間取得平衡，避免因過度追求效率而錯過潛在問題。
10. **假設每個AI應用都需關注**：
    - 假設所有AI應用都需要重視，即使是表面上無害或有益的用例，也可能隱含風險。
