# Creating AI Principles

## 道德問題辨識（issue spotting）的過程

1. **問題辨識的重要性**：
   - 辨識AI專案中的道德問題是AI治理的核心部分。
   - AI原則可作為辨識道德問題的指導方針。
2. **靈活性的重要性**：
   - 雖然使用清單或決策樹來快速辨識道德問題很有誘惑力，但這種方法無法涵蓋新技術和不同社會情境中出現的潛在問題。
   - 每個專案、客戶及社會背景都是獨特的，因此必須用靈活的方式來處理問題，而非簡單的是非判斷。
3. **道德問題的辨識過程**：
   - 辨識道德問題就像觀察鳥類一樣，隨著經驗增加，能看到的問題會越來越多。
   - 團隊合作能提高辨識問題的能力，因為沒有人能單獨發現所有問題。
4. **使用多種道德視角**：
   - 哲學家提供了多種道德視角（如後果主義、人權與義務、德性倫理），這些視角可以幫助從不同角度審視問題。
   - 使用這些視角並非選擇其中一種，而是根據情境選擇合適的視角來全面考量問題。
5. **參考資源**：
   - 提到Markkula應用倫理中心的材料可以幫助學習更多關於道德視角的內容。

## Google的人工智慧（AI）原則如何應用到AI的開發與應用中

1. **社會福祉**：AI應該促進健康的社會系統與機構，並避免不公平地拒絕人們獲得重要服務，如就業、住房、保險或教育。這項原則旨在減少對脆弱群體的風險和意外傷害。
2. **避免不公平偏見**：這項原則旨在促進AI的公平和公正，特別是避免訓練數據中的歷史性偏見影響結果，確保技術對所有用戶有用。
3. **安全性**：AI應該在開發和測試中注重安全性，防止對個人、社會系統和基礎設施造成傷害或中斷，並且對關鍵應用的行為進行有效監管。
4. **對人們負責**：AI應該尊重個人的權利和自主性，減少權力不平等，確保用戶有選擇不參與AI交互的權利，並提供報告誤用或誤操作的途徑。
5. **隱私保護**：保護個人和群體的隱私，確保對敏感數據的處理符合嚴格的安全標準，用戶對數據的使用有清晰的期望和知情同意。
6. **科學卓越**：追求科學上的卓越，確保AI技術發展基於嚴格的科學方法，並通過分享研究成果來避免偽科學的擴散。
7. **避免濫用**：Google致力於確保AI技術的有益用途，並且避免將技術應用於可能造成傷害或濫用的領域。

e.g. 圖片再貼標籤時只判斷西方婚紗西裝的圖片為婚禮，而其他國家傳統服飾卻被判斷成其他標籤，也是一種不好的行為

實現這些原則需要在AI生命週期的每個階段提出關鍵問題，以避免不公平和偏見的產生，並建立治理結構來進行審查和評估。

>[!NOTE]
>Google列出了四個AI應用領域是他們不會追求的：那些可能造成整體傷害的技術、旨在傷害他人的武器、違反國際標準的監控技術、以及違反國際法與人權的技術應用。

透過這些原則和程序，Google致力於以負責任的方式開發並應用AI技術。
