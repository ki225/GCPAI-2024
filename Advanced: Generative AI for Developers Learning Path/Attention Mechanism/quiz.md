What is the name of the machine learning technique that allows a neural network to focus on specific parts of an input sequence?

Attention mechanism

Long Short-Term Memory (LSTM)

Encoder-decoder

Convolutional neural network (CNN)
2.

What is the advantage of using the attention mechanism over a traditional sequence-to-sequence model?

The attention mechanism reduces the computation time of prediction.

The attention mechanism lets the model focus on specific parts of the input sequence.

The attention mechanism lets the model formulate parallel outputs.

The attention mechanism lets the model learn only short term dependencies.
3.

What are the two main steps of the attention mechanism?

Calculating the attention weights and generating the output word

Calculating the attention weights and generating the context vector

Calculating the context vector and generating the attention weights

Calculating the context vector and generating the output word
4.

How does an attention model differ from a traditional model?

The decoder does not use any additional information.

The traditional model uses the input embedding directly in the decoder to get more context.

The decoder only uses the final hidden state from the encoder.

Attention models pass a lot more information to the decoder.
5.

What is the name of the machine learning architecture that can be used to translate text from one language to another?

Convolutional neural network (CNN)

Encoder-decoder

Long Short-Term Memory (LSTM)

Neural network
6.

What is the advantage of using the attention mechanism over a traditional recurrent neural network (RNN) encoder-decoder?

The attention mechanism lets the decoder focus on specific parts of the input sequence, which can improve the accuracy of the translation.

The attention mechanism is more cost-effective than a traditional RNN encoder-decoder.

The attention mechanism requires less CPU threads than a traditional RNN encoder-decoder.

The attention mechanism is faster than a traditional RNN encoder-decoder.
7.

What is the purpose of the attention weights?

To calculate the context vector by averaging words embedding in the context.

To incrementally apply noise to the input data.

To generate the output word based on the input data alone.

To assign weights to different parts of the input sequence, with the most important parts receiving the highest weights.
