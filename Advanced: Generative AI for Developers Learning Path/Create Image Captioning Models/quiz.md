### 1. What is the name of the model that is used to generate text captions for images?
- [x] Encoder-decoder model
- [ ] Image generation model
- [ ] Bidirectional Encoder Representations from Transformers (BERT) model
- [ ] Image classification model

### 2. What is the purpose of the encoder in an encoder-decoder model?
- [ ] To generate text captions for the image.
- [ ] To translate text from one language to another.
- [ ] To answer your questions in an informative way, even if they are open ended, challenging, or strange.
- [x] To extract information from the image.

### 3. What is the purpose of the attention mechanism in an encoder-decoder model?
- [x] To allow the decoder to focus on specific parts of the image when generating text captions.
- [ ] To translate text from one language to another.
- [ ] To extract information from the image.
- [ ] To generate text captions for the image.

### 4. What is the goal of the image captioning task?
- [ ] To write different creative text formats, like poems, code, scripts, musical pieces, email, letters, etc.
- [x] To generate text captions for images.
- [ ] To translate text from one language to another.
- [ ] To answer your questions in an informative way, even if they are open ended, challenging, or strange.

### 5. What is the purpose of the decoder in an encoder-decoder model?
- [ ] To store the output data.
- [ ] To learn the relationship between the input and output data.
- [x] To generate output data from the information extracted by the encoder.
- [ ] To extract information from the input data.

### 6. What is the name of the dataset the video uses to train the encoder-decoder model?
- [x] COCO dataset.
- [ ] Fashion-MNIST dataset.
- [ ] ImageNet dataset.
- [ ] MNIST dataset.
