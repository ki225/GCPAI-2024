
### 編碼器-解碼器架構
- 編碼器-解碼器架構是一種序列到序列模型，將輸入序列（例如英語句子）轉換為輸出序列（例如法語翻譯）。
- 它也可以將發送到大型語言模型的提示作為輸入，並生成相應的回應。

### 工作原理
1. **編碼器階段**：
   - 生成輸入句子的向量表示。
   - 可以使用遞歸神經網絡（RNN）或變壓器（Transformer）塊來實現。
   - RNN逐個處理標記，並隨著每個標記更新其內部狀態。

2. **解碼器階段**：
   - 使用編碼器的向量生成輸出句子，同樣是逐步進行。
   - 解碼器也可以是RNN，逐個解碼標記。

### 訓練模型
- 訓練需要一個輸入-輸出對的數據集。
- 模型根據其生成的輸出與實際輸出之間的差異（誤差）調整權重。
- **教師強迫（Teacher Forcing）**：在解碼器的訓練過程中，提供正確的前一個標記作為輸入，而不是使用自己生成的輸出。

### 生成輸出
- 在生成過程中，解碼器接收編碼器的表示和一個特殊的開始標記（例如“GO”）。
- 過程包括：
  - 通過嵌入層表示開始標記。
  - 通過遞歸層更新狀態。
  - 使用softmax層生成單詞概率。
- 兩種選擇標記的方法：
  - **貪婪搜索（Greedy Search）**：選擇概率最高的標記。
  - **束搜索（Beam Search）**：評估標記序列的概率，而不是單個標記，以提高輸出質量。
![](greedy-beam.jpeg)
### 現代模型的差異
- 大型語言模型用變壓器塊替換編碼器-解碼器架構中的簡單RNN，利用注意力機制。
- 建議進一步學習的資源：關於注意力機制和變壓器模型的課程。

這種結構化的介紹為理解生成式AI和編碼器-解碼器架構的關鍵概念打下了堅實的基礎，這些概念對於使用大型語言模型至關重要。
